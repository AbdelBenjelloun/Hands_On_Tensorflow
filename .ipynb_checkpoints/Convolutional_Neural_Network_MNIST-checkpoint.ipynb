{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils \n",
    "import numpy.random as npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyCNN:    \n",
    "    ### 1.___ Initialize the class :\n",
    "    \"\"\"\n",
    "    scope -> name of scope to use for the variables of the model\n",
    "    data  -> tf.data containing image and label\n",
    "    summmaries_dir -> directory to store sumaries in case we want to use tensorboard\n",
    "    \"\"\"\n",
    "    def __init__(self, scope='network_CNN', num_classes=10,\n",
    "                 summaries_dir=None, training = False, keep_prob=0.5,\n",
    "                 learning_rate=0.01):\n",
    "        # variables of the model :\n",
    "        self.scope = scope\n",
    "        self.keep_prob = keep_prob\n",
    "        self._training = training\n",
    "        self._learning_rate = learning_rate\n",
    "        self.num_classes = num_classes\n",
    "        # Write tensorboard summaries :\n",
    "        self.summary_writer = None\n",
    "        #build model within scope, update summaries if needed :\n",
    "        with tf.variable_scope(scope):\n",
    "            #get the graph :\n",
    "            self.__build_model()\n",
    "            if summaries_dir :\n",
    "                # Get the directory for the summaries :\n",
    "                summary_dir = os.path.join(summaries_dir, \"summaries_{}\".format(scope))\n",
    "                # if directory doesnt exist -> create it :\n",
    "                if not os.path.exists(summary_dir):\n",
    "                    os.makedirs(summary_dir)\n",
    "                # Write summaries in summary_writer :\n",
    "                self.summary_writer = tf.summary.FileWriter(summary_dir)\n",
    "    \n",
    "    ### 2.____ Build the graph for the model :  \n",
    "    def  __build_model(self): \n",
    "        \n",
    "        #####_____________1. Placeholders for data _____________________________________\n",
    "        self.img = tf.placeholder(shape=[None, 84, 84, 4], dtype=tf.float32, name=\"image\")\n",
    "        self.label = tf.placeholder(shape=[10], dtype=tf.float32, name=\"label\")\n",
    "        \n",
    "        #####_____________2. Design the graph __________________________________________\n",
    "        with tf.variable_scope('CONV1', reuse=tf.AUTO_REUSE) as scope:\n",
    "            conv1 = tf.layers.conv2d(self.img, filters = 24, kernel_size = [3, 3], \\\n",
    "                                padding='SAME', activation=tf.nn.relu, name='conv1')\n",
    "        # Second Convolutional lyer :\n",
    "        with tf.variable_scope('CONV2', reuse=tf.AUTO_REUSE) as scope:\n",
    "            conv2 = tf.layers.conv2d(conv1, filters = 12, kernel_size = [3, 3], \\\n",
    "                                padding='SAME', activation=tf.nn.relu, name='conv2')\n",
    "        # Third a Fully-connected layer :\n",
    "        with tf.variable_scope('FC1', reuse=tf.AUTO_REUSE) as scope:\n",
    "            flattened = tf.contrib.layers.flatten(conv2)\n",
    "            fc1 = tf.contrib.layers.fully_connected(flattened, 512)\n",
    "        # Dropout :\n",
    "        with tf.variable_scope('DROPOUT', reuse=tf.AUTO_REUSE) as scope:\n",
    "            fc1 = tf.layers.dropout(fc1, self.keep_prob, training=self._training, name='Dropout') \n",
    "            \n",
    "        with tf.variable_scope('FC2', reuse=tf.AUTO_REUSE) as scope:\n",
    "            fc2 = tf.contrib.layers.fully_connected(fc1, 10)\n",
    "            self.logits_ = fc2\n",
    "        \n",
    "        with tf.variable_scope('probabilities', reuse=tf.AUTO_REUSE) as scope:\n",
    "            self.probabilities = tf.nn.softmax(self.logits_)\n",
    "        \n",
    "        #####_____________3. Get the loss and define the optimization operation : ______\n",
    "        # define the loss :\n",
    "        with tf.variable_scope('loss', reuse=tf.AUTO_REUSE) as scope:\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( \\\n",
    "                                    logits=self.logits_, labels=self.label))\n",
    "        \n",
    "        with tf.variable_scope('OPT', reuse=tf.AUTO_REUSE) as scope:\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=self._learning_rate)\n",
    "            self.train = self.optimizer.minimize(self.loss)\n",
    "                \n",
    "        # _____________4. Summaries for Tensorboard : __________________________________\n",
    "        self.summaries = tf.summary.merge([tf.summary.scalar(\"loss\", self.loss)])\n",
    "        \n",
    "        \n",
    "    ### 3.____ Prediction function :\n",
    "    \"\"\"\n",
    "    sess -> tf.Session() to run the graph\n",
    "    images -> set of images that we want to classify\n",
    "    \"\"\"\n",
    "    def predict(self, images):\n",
    "        self._training = False \n",
    "        with tf.Session() as sess :\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            prediction = sess.run(tf.argmax(self.probabilities), {self.img: images})\n",
    "            return prediction    \n",
    "    \n",
    "    \"\"\"\n",
    "    images, labels = data to train with\n",
    "    \"\"\"\n",
    "    def train_step(self, sess, images, labels):\n",
    "        \n",
    "        self._training = True\n",
    "        feed_dict = {self.img: images, self.label: labels}\n",
    "        summaries, _, loss = sess.run([self.summaries, self.train, self.loss], feed_dict)\n",
    "        \n",
    "        if self.summary_writer:\n",
    "            self.summary_writer.add_summary(summaries)\n",
    "        return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x = npr.randint(2, size=[1,84,84,4])\n",
    "y = npr.randint(2, size=[10])\n",
    "\n",
    "model = MyCNN(scope='a')\n",
    "model.predict(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    model.train_step(sess, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
