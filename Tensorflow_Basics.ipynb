{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Imports :\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session/Tensors examples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "## First session/tensors:\n",
    "\n",
    "a = tf.add(3, 5)\n",
    "print(a)\n",
    "print('\\n')\n",
    "## return the tensor a not the value ! \n",
    "## To se the value need to create a session :\n",
    "sess = tf.Session()\n",
    "print(sess.run(a))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "## different way to create a session :\n",
    "with tf.Session() as sess :\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frist_op :  -1201670133\n",
      "second_op :  351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n  Note :\\n  \\n  if for example we on ly want the value of pow_op, \\n  to compute this value we don't need to compute the value of useless\\n  tensorflow will save the computation and ignore useless !\\n  \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Graph :\n",
    "x = 13\n",
    "y = 1\n",
    "\n",
    "add_op = tf.add(2*x, y)\n",
    "mul_op = tf.multiply(x, y)\n",
    "useless = tf.multiply(mul_op, add_op)\n",
    "pow_op = tf.pow(add_op, mul_op)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    z, not_useless = sess.run([pow_op, useless])\n",
    "\n",
    "print('frist_op : ', z)\n",
    "print('second_op : ', not_useless)\n",
    "\n",
    "'''\n",
    "  Note :\n",
    "  \n",
    "  if for example we on ly want the value of pow_op, \n",
    "  to compute this value we don't need to compute the value of useless\n",
    "  tensorflow will save the computation and ignore useless !\n",
    "  \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations : Constant - Variables - Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "## Tensorboard graph visualization with names...\n",
    "a = tf.constant(2, name='a')\n",
    "b = tf.constant(3, name='b')\n",
    "x = tf.add(a, b, name='add')\n",
    "# summary writer creation for tensorboard :\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix multiplication : \n",
      " [[ 3  8]\n",
      " [ 1 18]]\n",
      "zeros matrix : \n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "lin space : \n",
      " [ 5.        7.666667 10.333334 13.      ]\n",
      "range : \n",
      " [0 1 2 3 4]\n",
      "range with diff: \n",
      " [ 5 15 25 35 45]\n"
     ]
    }
   ],
   "source": [
    "## Constants :\n",
    "'''\n",
    "tf.constant(\n",
    "            value,\n",
    "            dtype=None,\n",
    "            shape=None,\n",
    "            name='Const',\n",
    "            verify_shape=False\n",
    "            )\n",
    "'''\n",
    "\n",
    "a = tf.constant([1,2])\n",
    "b = tf.constant([[3,4],[1,9]])\n",
    "x = tf.multiply(a,b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #matrix multplication with tensors\n",
    "    print('matrix multiplication : \\n', sess.run(x))\n",
    "    # zeros matrix :\n",
    "    print('zeros matrix : \\n', sess.run(tf.zeros([3,4])))\n",
    "    # lin space :\n",
    "    print('lin space : \\n', sess.run(tf.lin_space(5.0, 13.0, 4)))\n",
    "    # range :\n",
    "    print('range : \\n', sess.run(tf.range(5)))\n",
    "    print('range with diff: \\n', sess.run(tf.range(5, 50, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First evaluation of a variable : \n",
      " [[2 5]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "## Variables :\n",
    "'''\n",
    "Variable is a class with different operations while constant is only an operation !\n",
    "get_Variable is better than Variable : allow to share data...\n",
    "variables need initialization in order to compute -> done inside the session for all variables\n",
    "'''\n",
    "\n",
    "## First evaluation of a variable\n",
    "var = tf.Variable(tf.constant([[2,5],[1,1]]))\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('First evaluation of a variable : \\n', var.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firt evaluation before running the op : \n",
      " 10\n",
      "second evaluation before running the op : \n",
      " 30\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Define an operation that will be run multiple times \n",
    "need to precise it inside the session !\n",
    "'''\n",
    "    \n",
    "## assign op\n",
    "var = tf.Variable(10)\n",
    "assign_op = var.assign(30)\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('firt evaluation before running the op : \\n', var.eval())\n",
    "    ## run the assign op :\n",
    "    sess.run(assign_op)\n",
    "    print('second evaluation before running the op : \\n', var.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firt evaluation before running the op : \n",
      " 10\n",
      "second assign before running the op : \n",
      " 20\n",
      "second assign before running the op : \n",
      " 40\n"
     ]
    }
   ],
   "source": [
    "var = tf.Variable(10)\n",
    "assign_op = var.assign(2*var)\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('firt evaluation before running the op : \\n', var.eval())\n",
    "    ## run the assign op :\n",
    "    sess.run(assign_op)\n",
    "    print('second assign before running the op : \\n', var.eval())\n",
    "    ## run the assign op :\n",
    "    sess.run(assign_op)\n",
    "    print('second assign before running the op : \\n', var.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "var = tf.Variable(10)\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # add value :\n",
    "    sess.run(var.assign_add(17))\n",
    "    print(var.eval())\n",
    "    # substruct value\n",
    "    sess.run(var.assign_sub(13))\n",
    "    print(var.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8. 7. 6.]\n",
      "\n",
      "\n",
      "run miultiple times with different values : \n",
      "\n",
      "[6. 6. 6.]\n",
      "[ 9. 11.  6.]\n",
      "[7. 7. 6.]\n",
      "[13. 12.  6.]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Placeholder give space to feed later : \n",
    "    like defining an input variable in python f(x,y) =.. \n",
    "    we give space to x and y to feed later\n",
    "'''\n",
    "\n",
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "b = tf.constant([5,5,5], tf.float32)\n",
    "\n",
    "def f(a):\n",
    "    return a + b\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    print( sess.run( f(a), feed_dict={a: [3, 2, 1]} ) )\n",
    "    print('\\n')\n",
    "\n",
    "## run miultiple times with different values :\n",
    "print('run miultiple times with different values : \\n')\n",
    "list_of_values = [[1, 1, 1], [4, 6, 1], [2, 2, 1], [8, 7, 1]]\n",
    "with tf.Session() as sess :\n",
    "    for value in list_of_values:\n",
    "        print( sess.run( f(a), feed_dict={a: value} ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "## Feeding : useful for testing a part of a graph or certain operations\n",
    "a = tf.add(2, 3)\n",
    "b = tf.multiply(a, 2)\n",
    "with tf.Session() as sess:\n",
    "    # compute the value of b given a is 10\n",
    "    print( sess.run(b, feed_dict={a: 10}) )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get_variable :\n",
    "\n",
    "The use of tf.get_variable is better than tf.variable :\n",
    "\n",
    "    - Get_variable allow the model to reuse the same var (save space) and to save the model with this value\n",
    "    \n",
    "    !!! Name of the variable is very important and should be unique !!!\n",
    "    \n",
    "How to use it ex :\n",
    "\n",
    "1. my_variable = tf.get_variable(\"my_variable\", [1, 2, 3]) -> with [1,2,3] is the shape of the tensor\n",
    "2. tf.get_variable(\"myy_variable\", [1, 2, 3], initializer=tf.zeros_initializer) -> initialize at zero \n",
    "3. other_variable = tf.get_variable(\"other_variable\", dtype=tf.int32, initializer=tf.constant([23, 42])) -> constant initialization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First evaluation of a variable : \n",
      " [0.]\n"
     ]
    }
   ],
   "source": [
    "#var = tf.Variable(tf.constant([[2,5],[1,1]]))\n",
    "var1 = tf.get_variable(\"my_new_var\", [1], initializer=tf.zeros_initializer)\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #print('First evaluation of a variable : \\n', var.eval())\n",
    "    print('First evaluation of a variable : \\n', var1.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-662c2fe27903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'two_layers'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#define the scope in order to reuse the variables :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlogits1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHidden_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#Allows to reuse the same weights for logits2 - otherwise error weights already used!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mlogits2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHidden_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x1' is not defined"
     ]
    }
   ],
   "source": [
    "## let's consider the following function \n",
    "\n",
    "###__ First try \n",
    "def Hidden_layers(x):\n",
    "    \n",
    "    assert x.shape.as_list() == [200, 100]\n",
    "\n",
    "    # If we use variable instead of get_varibale the model will initialize w and b at each call \n",
    "    w1 = tf.get_variable(\"h1_weights\", [100, 50], initializer=tf.random_normal_initializer())\n",
    "    b1 = tf.get_variable(\"h1_biases\", [50], initializer=tf.constant_initializer(0.0))\n",
    "    h1 = tf.matmul(x, w1) + b1\n",
    "\n",
    "    assert h1.shape.as_list() == [200, 50]  \n",
    "\n",
    "    w2 = tf.get_variable(\"h2_weights\", [50, 10], initializer=tf.random_normal_initializer())\n",
    "    b2 = tf.get_variable(\"h2_biases\", [10], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    logits = tf.matmul(h1, w2) + b2\n",
    "    return logits\n",
    "\n",
    "\n",
    "with tf.variable_scope('two_layers') as scope:  #define the scope in order to reuse the variables :\n",
    "    \n",
    "    logits1 = Hidden_layers(x1)\n",
    "    scope.reuse_variables()   #Allows to reuse the same weights for logits2 - otherwise error weights already used!\n",
    "    logits2 = Hidden_layers(x2)\n",
    "\n",
    "\n",
    "#******************************* best way to share variables (reuse the same model) ********************    \n",
    "###__ In the previous we should write scope.reuse_variables() at each time we need to reuse them -> not efficient!\n",
    "### we can specify resue when we creat the variables :\n",
    "\n",
    "def FC(x, output_dim, scope):\n",
    "    \n",
    "    ##create variables within a scope and specify reuse :\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE) as scope:\n",
    "\n",
    "        w = tf.get_variable(\"weights\", [x.shape[1], output_dim], initializer=tf.random_normal_initializer())\n",
    "        b = tf.get_variable(\"biases\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.matmul(x, w) + b\n",
    "\n",
    "def two_hidden_layers(x):\n",
    "    h1 = FC(x, 50, 'h1')\n",
    "    h2 = FC(h1, 10, 'h2')\n",
    "\n",
    "with tf.variable_scope('two_layers') as scope:\n",
    "    logits1 = two_hidden_layers(x1)\n",
    "    logits2 = two_hidden_layers(x2)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deal with Dataset :\n",
    "\n",
    "\n",
    "Performs quicker than Placeholder biut can be tricky to use if there is a lot of preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples :  190\n",
      "\n",
      " \n",
      "\n",
      "small view of data : \n",
      " [[ 1.822   74.82825]\n",
      " [ 3.869   70.81949]\n",
      " [ 3.911   72.15066]]\n"
     ]
    }
   ],
   "source": [
    "data_path = '/Users/benjelloun/Documents/General_code/Hands_On_Tensorflow/data/birth_life_2010.txt'\n",
    "\n",
    "# Step 1: Get the data == read in data from the .txt file\n",
    "data, n_samples = utils.read_birth_life_data(data_path)\n",
    "print('number of samples : ', n_samples)\n",
    "print('\\n \\n')\n",
    "print('small view of data : \\n', data[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output type :  (tf.float32, tf.float32)\n",
      "\n",
      "\n",
      "Output shape :  (TensorShape([]), TensorShape([]))\n",
      "\n",
      "\n",
      "Iterator data\n",
      "[1.822, 74.82825]\n",
      "[3.869, 70.81949]\n",
      "[3.911, 72.15066]\n"
     ]
    }
   ],
   "source": [
    "## STORE DATA in tf.data.Dataset((features, labels)) :\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))\n",
    "\n",
    "# METHODS :\n",
    "print('Output type : ', dataset.output_types)\n",
    "print('\\n')\n",
    "print('Output shape : ', dataset.output_shapes)\n",
    "print('\\n')\n",
    "\"\"\"\n",
    "tf.data.TextLineDataset(filenames)\n",
    "tf.data.FixedLengthRecordDataset(filenames)\n",
    "tf.data.TFRecordDataset(filenames)\n",
    "\"\"\"\n",
    "\n",
    "# OPERATIONS - ITERATOR :\n",
    "\n",
    "\"\"\"\n",
    "Iterates through the dataset exactly once. No need to initialization :\n",
    "    - iterator = dataset.make_one_shot_iterator() \n",
    "\n",
    "Iterates through the dataset as many times as we want. Need to initialize with each epoch :\n",
    "    - iterator = dataset.make_initializable_iterator()\n",
    "\"\"\"\n",
    "iterator = dataset.make_one_shot_iterator() \n",
    "X,Y = iterator.get_next() \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('Iterator data')\n",
    "    print(sess.run([X, Y])) # >> [1.822, 74.82825]\n",
    "    print(sess.run([X, Y])) # >> [3.869, 70.81949]\n",
    "    print(sess.run([X, Y]))\n",
    "    \n",
    "## Methods :\n",
    "#dataset = dataset.shuffle(1000)  ## shuffle the dataset\n",
    "#dataset = dataset.repeat(100)\n",
    "#dataset = dataset.batch(128) ##-> Convert the dataset into batches of size 128\n",
    "#dataset = dataset.map(lambda x: tf.one_hot(x, 10))  #convert each elem of dataset to one_hot vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optimizers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.__ define the optimizer :\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "2.__ run the optimizer into a Session :\n",
    "_, l = sess.run([optimizer, loss], feed_dict={X: x, Y:y})\n",
    "\n",
    "How it does work :\n",
    "    Session looks at all trainable variables that loss depends on and update them (should specigy trianable=True is we want to train a variable!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## opt = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "## within the session _,loss_ = sess.run([opt, loss]..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save-Restore models\n",
    "\n",
    "    - Save line : tf.train.Saver.save(sess, save_path, global_step=None...)\n",
    "\n",
    "    - restore line : tf.train.Saver.restore(sess, save_path)\n",
    "\n",
    "\n",
    "Note : save will save the weights and not the graph, in adition it will save a checkpoint file which can map variables name to tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##___________ Save a model after a certain number of iterations :\n",
    "\n",
    "\n",
    "\n",
    "#call the model : for ex MyModel\n",
    "model = MyModel(parameters)\n",
    "# create a saver object\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    for step in range(training_steps):\n",
    "        # optimizaiton step\n",
    "        sess.run([optimizer])\n",
    "        \n",
    "        # save the model after n steps\n",
    "        if step%n == 0:\n",
    "            \n",
    "            saver.save(sess, 'checkpoint_directory/model_name', global_step=step)\n",
    "\n",
    "        \n",
    "##___________ Load a model after a certain number of iterations :  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Neural Networks functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 2.___ Convolution layer :\n",
    "# perform a convolution\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=image,\n",
    "                        filters = 32,\n",
    "                        kernel_size = [5, 5],\n",
    "                        padding='SAME',\n",
    "                        activation=tf.nn.relu,\n",
    "                        name='conv1')\n",
    "\n",
    "# Pooling operation :\n",
    "pool1 = tf.layers.max_pooling2d(inputs=input, \n",
    "                                pool_size=[2, 2], \n",
    "                                strides=2,\n",
    "                                name='pool1')\n",
    "\n",
    "# Dense layer :\n",
    "fc = tf.layers.dense(input, 1024, activation=tf.nn.relu, name='fc')\n",
    "\n",
    "# Dropout :\n",
    "dropout = tf.layers.dropout(fc, self.keep_prob, training=self.training, name='dropout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TF-Records\n",
    "\n",
    "    - Make better use of disk cache\n",
    "    - Faster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
